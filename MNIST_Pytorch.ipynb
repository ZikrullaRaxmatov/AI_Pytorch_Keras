{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa+grbR9RDrQoNO5tU9ff9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZikrullaRaxmatov/AI_Pytorch_Keras/blob/main/MNIST_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Template\n",
        "1. import libraries\n",
        "2. dataset load\n",
        "3. data preparation / procces\n",
        "4. model create\n",
        "5. train the model\n",
        "6. predict (with test dataset)\n",
        "7. evaluate the model"
      ],
      "metadata": {
        "id": "jhxwyRJRg4AK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TiBxDh9CT8DK"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset load\n",
        "class MNISTDataset(Dataset):\n",
        "  def __init__(self, csv_file, transform = None):\n",
        "    self.data = pd.read_csv(csv_file).values\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = self.data[idx, 1:].astype(np.uint8).reshape(28, 28, 1)\n",
        "    label = self.data[idx, 0].astype(np.int64)\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    return img, label\n",
        "\n"
      ],
      "metadata": {
        "id": "itmK9t5TUVzb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation / proccesing\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=0.5, std=0.5)])\n",
        "\n",
        "train_dataset = MNISTDataset('./sample_data/mnist_train_small.csv', transform=transform)\n",
        "test_dataset = MNISTDataset('./sample_data/mnist_test.csv', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "7Tl-Hr4-UVwl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.data.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PdWYVoVj2af",
        "outputId": "01857290-bb06-4f0d-c311-25c92716ca8f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19999, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in train_loader:\n",
        "  print(img.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku9kOqz3gUqo",
        "outputId": "97e839a9-3b84-4c23-c3b0-3a95947d64d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model create\n",
        "class CNNPytorch(torch.nn.Module):\n",
        "  def __init__(self, num_classes = 10):\n",
        "    super(CNNPytorch, self).__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
        "    self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
        "    self.pool = torch.nn.MaxPool2d(kernel_size=2)\n",
        "    self.flatten = torch.nn.Flatten()\n",
        "    self.fc = torch.nn.Linear(64*5*5, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))\n",
        "    x = self.pool(torch.relu(self.conv2(x)))\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc(x)\n",
        "    return torch.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "model = CNNPytorch()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Model is running on: {device}\")\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "HqfIV8cogUoR",
        "outputId": "a65078f1-1b69-4689-cc6d-b51d2a761f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is running on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6Uc5kEegUlu",
        "outputId": "cd839bb8-93f4-4845-f45e-43bcde3684c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNPytorch(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc): Linear(in_features=1600, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "\n",
        "  running_loss = 0.\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for epoch_idx, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    _, predicts = torch.max(outputs, 1)\n",
        "    total += label.size(0)\n",
        "    correct += (predicts == labels).sum().item()\n",
        "\n",
        "    if (epoch_idx + 1) % 312 == 0:\n",
        "      print(f\"Epochs: {epoch+1} / {epochs}\")\n",
        "      print(f\"loss: {running_loss/100:.4f} - accuracy: {correct/total:.4f}\")\n",
        "\n",
        "      running_loss = 0.\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YTr8X5bInn3q",
        "outputId": "f0fc5315-1211-4d16-d1cd-2db76e454471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 / 5\n",
            "loss: 5.3810 - accuracy: 0.7569\n",
            "Epochs: 2 / 5\n",
            "loss: 5.3494 - accuracy: 0.7622\n",
            "Epochs: 3 / 5\n",
            "loss: 5.3285 - accuracy: 0.7663\n",
            "Epochs: 4 / 5\n",
            "loss: 5.3122 - accuracy: 0.7681\n",
            "Epochs: 5 / 5\n",
            "loss: 5.3007 - accuracy: 0.7707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicts = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicts == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f\"Accuracy: {accuracy:.2f} %\")\n"
      ],
      "metadata": {
        "id": "GIsqdJBPnnzk",
        "outputId": "6e2a274f-d11a-439e-e5f1-05e2fc7ca4c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 77.27 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5zbzDybnnuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vj1_yQpannp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}